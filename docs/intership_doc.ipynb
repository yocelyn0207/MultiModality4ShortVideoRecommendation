{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Project Description\n",
    "\n",
    "This project aims to optimise short-video recommendation using multi-modal\n",
    "information.\n",
    "\n",
    "# Data preparation\n",
    "\n",
    "We need to prepare four parts of data.\n",
    "\n",
    "**Part 1**: videos. Prefer in `.mp4` format.\n",
    "\n",
    "**Part 2**: musics. Prefer in `.wav` format.\n",
    "\n",
    "**Part 3**: interaction information of users and videos. Please include\n",
    "following fields, and save in a `.csv` file.\n",
    "The illustrations of data type and content are as below.\n",
    "\n",
    "\n",
    "| Field       | Data Type     | Content  |\n",
    "| ------------|:--------------| :-----|\n",
    "| userID      | string or int | the user's ID |\n",
    "| userGender  | string        | the user's gender |\n",
    "| userAge     | int           | the user's age |\n",
    "| userLocation| string        | the user's location |\n",
    "| videoID     | string or int | the video's ID |\n",
    "| liveScores  | float         | the video's live score |\n",
    "| finish      | int           | whether the user finishes the video, if is use 1, otherwise 0 |\n",
    "| like        | int           | whether the user likes the video, if is use 1, otherwise 0 |\n",
    "| favorites   | int           | whether the user favorites the video, if is use 1, otherwise 0 |\n",
    "| forward     | int           | whether the user forwards the video, if is use 1, otherwise 0 |\n",
    "\n",
    "Specifically, the live score of a short video is calculated as following:\n",
    "\n",
    "$\\frac{1}{n}\\sum \\limits_{n=1} \\frac{finish_n + 1.2 like_n + 1.2favourite_n + 0.8forward_n}{finish_n + like_n + favourite_n+forward_n}$\n",
    "\n",
    "where $n$ is the number of users that have interacted with this short video till now.\n",
    "\n",
    "\n",
    "**Part 4**: videos information. Please include following fields, and save\n",
    "in a `.csv` file.\n",
    "The illustrations of data type and content are as below.\n",
    "\n",
    "\n",
    "| Field        | Data Type           | Content  |\n",
    "| ------------- |:-------------| :-----|\n",
    "| videoID      | string or int |the video's ID|\n",
    "| musicID      | string or int |ID of the video's music|\n",
    "| videoLocation | string      |the video's location|\n",
    "| description | string      |the video's descriptions |\n",
    "| comment1 | string      |the video's top comment |\n",
    "| comment2 | string      |the video's second top comment |\n",
    "| comment3 | string      |the video's third top comment|\n",
    "| comment4 | string      |the video's fourth top comment |\n",
    "| comment5 | string      |the video's fifth top comment|\n",
    "| hot | int      |whether the video is on the hot list, if is use 1, otherwise 0 |\n",
    "| entertainmentHot | int      |whether the video is on the entertainment hot list, if is use 1, otherwise 0 |\n",
    "| socialHot | int      |whether the video is on the social hot list, if is use 1, otherwise 0|\n",
    "| challengeHot | int      |whether the video is on the challenge hot list, if is use 1, otherwise 0|\n",
    "| authorHot | int      |whether the video is on the author hot list, if is use 1, otherwise 0|\n",
    "| authorID | string or int      |the author's ID|\n",
    "| authorGender | string      |the author's gender|\n",
    "| authorAge | int      |the author's age|\n",
    "| authorLocation | string      |the author's location|\n",
    "\n",
    "# Model Structure\n",
    "\n",
    "We use a BERT-based model to do self-attention cross modalities. The input for\n",
    "our model is as following.\n",
    "\n",
    "![input](./docs/input.png)\n",
    "\n",
    "## Input\n",
    "\n",
    "We use three parts of information as the input——the user, the author and the video\n",
    "information——to predict whether we should recommend a short video to a user or not.\n",
    "\n",
    "With regards to the video part, we preprocess it to get three kinds of information as parts\n",
    "of our input - semantics, actions and music.\n",
    "To get semantic information, we extract subtitles from key frames, as well as semantic\n",
    "features using S3D which is pretrained to generate video titles.\n",
    "To get action information, we extract action features using 3D-ResNet which is pretrained\n",
    "to classify actions of human beings and animals.\n",
    "To get music information, we extract music features using Wav2Vec which is pretrained\n",
    "on songs.\n",
    "\n",
    "Among all the above information, there are three types of data - text, categorical, and\n",
    "numerical. As to the text input, we use get word embeddings from pretrained BERT model.\n",
    "As to the categorical input, we use different embedding layers to encode each category.\n",
    "As to the numerical input, we employ a MLP to transform it into desired input embeddings.\n",
    "\n",
    "## Label\n",
    "\n",
    "The goal of this model is to predict whether we should recommend a short video to a\n",
    "user. The ground truth label is 1 for yes and 0 for no. We label a data as 1 as long\n",
    "as the user has one of these actions-finish, like, favorite, or forward.\n",
    "\n",
    "## Loss function\n",
    "\n",
    "We feed the last hidden state of [CLS] token into a classifier, which has two feed-forward\n",
    "layers and one fully-connected layer, to predict the label. The loss function is\n",
    "cross-entropy.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Feature work\n",
    "\n",
    "We were intended to separate narrations in the audio from the music in it which has a vocal\n",
    "track, but didn't find available pretrained models. We consider involving the narrations\n",
    "features as input would enhance the model's performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}